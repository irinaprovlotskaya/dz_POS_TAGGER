{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dz2_pos_tagger.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P9bQimHRKoF",
        "outputId": "bb2b0906-d7c9-4305-ea76-7606e8ef3363"
      },
      "source": [
        "pip install csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement csv (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for csv\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGDjE5WnRNLX"
      },
      "source": [
        "import csv"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZYTKhL5dM1P"
      },
      "source": [
        "Открываю вручную размеченный корпус. Так называемы Золотой Стандарт. Была выбрана экономическая статья, так как в ней есть несколько аббревиатур, например ООН, также были слова с дефисом. Разметка - Universal Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU9vfm2_NSGW"
      },
      "source": [
        "with open ('hand_rasmetka.csv', 'r', encoding = 'utf-8') as tt:\n",
        "  reader = csv.reader(tt)\n",
        "  ideal = []\n",
        "  for row in reader:\n",
        "    ideal.append(row)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeuUxsr-SD5w"
      },
      "source": [
        "with open ('text_for_dz.txt', 'r', encoding = 'utf-8') as pos:\n",
        "    text = pos.read()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKOnw-Tvf37Q"
      },
      "source": [
        "Я выбрала такие POS теггеры: natasha, spacy, mystem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChqYkhs99c88"
      },
      "source": [
        "!pip install -U spacy>=3.0"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NABKFOb9dGd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a7ed2f8-6325-4c30-a742-fd6e29b14e67"
      },
      "source": [
        "!python -m spacy download ru_core_news_md"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ru-core-news-md==3.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_md-3.1.0/ru_core_news_md-3.1.0-py3-none-any.whl (42.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.7 MB 2.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from ru-core-news-md==3.1.0) (3.1.3)\n",
            "Collecting pymorphy2>=0.9\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7.1\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 48.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2>=0.9->ru-core-news-md==3.1.0) (0.6.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (57.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (1.0.5)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (3.7.4.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (0.8.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.11.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (1.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (3.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (8.0.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.0.5)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (0.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (21.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (4.62.3)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (0.4.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (0.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (5.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->ru-core-news-md==3.1.0) (2.0.1)\n",
            "Installing collected packages: pymorphy2-dicts-ru, dawg-python, pymorphy2, ru-core-news-md\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 ru-core-news-md-3.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_md')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vo8NI1Q9j_O"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEBGr0eN9kDO"
      },
      "source": [
        "nlp = spacy.load('ru_core_news_md')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAb-zqxB9kFq"
      },
      "source": [
        "document = nlp(text)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlWACwh29kIx"
      },
      "source": [
        "result_spacy = []\n",
        "for token in document:\n",
        "  result_spacy.append([token.text, token.pos_])  "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLeFXgALeJrq"
      },
      "source": [
        "Далее идет анализ mystem. У меня получилось так, что mystem не работает в Google Colab, поэтому я прогнала текст в Jupyter и сделала выгрузку в test.csv. Я не сделала все дз в Jupyter, потому что в нем у меня работает spacy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCg8qSHx9t5_"
      },
      "source": [
        "pip install pymystem3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4E9u_jI9uD9"
      },
      "source": [
        "from pymystem3 import Mystem\n",
        "m = Mystem()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag_Qas7E9uGW"
      },
      "source": [
        "ana = m.analyze(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0O74qpu9uJH"
      },
      "source": [
        "result_mystem = []\n",
        "for word in ana:\n",
        "    if 'analysis' in word:\n",
        "        gr = word['analysis'][0]['gr']\n",
        "        pos = gr.split('=')[0].split(',')[0]\n",
        "        result_mystem.append([word['text'],pos])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaw28cVb95mc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "e8a25cb5-7a6b-4116-e360-1ea242c916b4"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(result_mystem)\n",
        "df.to_csv('test.csv', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-54784361c4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_mystem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result_mystem' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zMftspKhzOA"
      },
      "source": [
        "with open ('test.csv', 'r', encoding = 'utf-8') as tt2:\n",
        "  reader = csv.reader(tt2)\n",
        "  result_of_mystem = []\n",
        "  for row in reader:\n",
        "    result_of_mystem.append(row)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KF2t6yA2kaTK",
        "outputId": "7c17e67d-d9e1-4b14-ba4a-7da3fc44e262"
      },
      "source": [
        "pip install natasha"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.4.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 34.4 MB 29 kB/s \n",
            "\u001b[?25hCollecting navec>=0.9.0\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting yargy>=0.14.0\n",
            "  Downloading yargy-0.15.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 139 kB/s \n",
            "\u001b[?25hCollecting razdel>=0.5.0\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.7/dist-packages (from natasha) (0.9.1)\n",
            "Collecting slovnet>=0.3.0\n",
            "  Downloading slovnet-0.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.4 MB/s \n",
            "\u001b[?25hCollecting ipymarkup>=0.8.0\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting intervaltree>=3\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from navec>=0.9.0->natasha) (1.19.5)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (0.6.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from pymorphy2->natasha) (2.4.417127.4579844)\n",
            "Building wheels for collected packages: intervaltree\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26119 sha256=0e6089ea6499e5604b87c0260ced3e72f96aeeb74955346c4e46f25d9de9e46f\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/85/bd/1001cbb46dcfb71c2001cd7401c6fb250392f22a81ce3722f7\n",
            "Successfully built intervaltree\n",
            "Installing collected packages: razdel, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "  Attempting uninstall: intervaltree\n",
            "    Found existing installation: intervaltree 2.1.0\n",
            "    Uninstalling intervaltree-2.1.0:\n",
            "      Successfully uninstalled intervaltree-2.1.0\n",
            "Successfully installed intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.4.0 navec-0.10.0 razdel-0.5.0 slovnet-0.5.0 yargy-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUFdqtuTkefp"
      },
      "source": [
        "from natasha import Segmenter, NewsEmbedding, NewsMorphTagger, Doc\n",
        "segmenter = Segmenter()\n",
        "\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caS-wFSvlLhv"
      },
      "source": [
        "from natasha import (\n",
        "    Segmenter,\n",
        "    NewsEmbedding,\n",
        "    NewsMorphTagger,\n",
        "    Doc)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51TNa_ghlM6a"
      },
      "source": [
        "segmenter = Segmenter()\n",
        "\n",
        "emb = NewsEmbedding()\n",
        "morph_tagger = NewsMorphTagger(emb)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-AQstmlk27T"
      },
      "source": [
        "doc = Doc(text)\n",
        "doc.segment(segmenter) \n",
        "doc.tag_morph(morph_tagger)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkN6p9hSkepT"
      },
      "source": [
        "result_natasha = []\n",
        "for token in doc.tokens:\n",
        "    result_natasha.append([token.text, token.pos])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pGcZTGmexja"
      },
      "source": [
        "Далее я привожу все к единому стандарту, а именно Universal Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znz5VkS5iyR1"
      },
      "source": [
        "for e in range(len(result_of_mystem)):\n",
        "  if result_of_mystem[e][1] == 'A':\n",
        "    result_of_mystem[e][1] = 'ADJ'\n",
        "  if result_of_mystem[e][1] == 'CONJ':\n",
        "    result_of_mystem[e][1] = 'CCONJ'\n",
        "  if result_of_mystem[e][1] == 'S':\n",
        "    result_of_mystem[e][1] = 'NOUN'\n",
        "  if result_of_mystem[e][1] == 'V':\n",
        "    result_of_mystem[e][1] = 'VERB'\n",
        "  if result_of_mystem[e][1] == 'ANUM':\n",
        "    result_of_mystem[e][1] = 'NUM'\n",
        "  if result_of_mystem[e][1] == 'PR':\n",
        "    result_of_mystem[e][1] = 'ADP'\n",
        "  if result_of_mystem[e][1] == 'APRO':\n",
        "    result_of_mystem[e][1] = 'PRON'\n",
        "  if result_of_mystem[e][1] == 'PART':\n",
        "    result_of_mystem[e][1] = 'x'"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhAgHoNPe-Jo"
      },
      "source": [
        "Accuracy Mystem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvwhrKm1tRwS"
      },
      "source": [
        "result_mystem_hand = []\n",
        "for c1 in ideal:\n",
        "  for x1 in result_of_mystem:\n",
        "    if c1 == x1:\n",
        "      result_mystem_hand.append(c1)\n",
        "      break\n",
        "correct_mystem = (len(result_mystem_hand))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhBTC85i_WvX"
      },
      "source": [
        "accuracy_mystem = correct_mystem/236*100"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFBAk0hqfF16"
      },
      "source": [
        "Accuracy spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snqPTKzFdCGV"
      },
      "source": [
        "result_spacy_hand = []\n",
        "for c2 in ideal:\n",
        "  for x2 in result_spacy:\n",
        "    if c2 == x2:\n",
        "      result_spacy_hand.append(c2)\n",
        "      break\n",
        "correct_spacy = (len(result_spacy_hand))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDXg3i3HeU2B"
      },
      "source": [
        "accuracy_spacy = correct_spacy/236*100"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUBrOMXpfbfL"
      },
      "source": [
        "Accuracy Natasha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWVSjwGFmHE6"
      },
      "source": [
        "result_natasha_hand = []\n",
        "for c4 in ideal:\n",
        "  for x4 in result_natasha:\n",
        "    if c4 == x4:\n",
        "      result_natasha_hand.append(c4)\n",
        "      break\n",
        "correct_natasha = (len(result_natasha_hand))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcVa9xJHmao9"
      },
      "source": [
        "accuracy_natasha = correct_natasha/236*100"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgqV7koBffdw"
      },
      "source": [
        "Лучшим теггером получился spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZrIdN_2me1T",
        "outputId": "7f671e26-66a6-47ca-d01d-984a7cd5da7b"
      },
      "source": [
        "print(accuracy_mystem)\n",
        "print(accuracy_natasha)\n",
        "print(accuracy_spacy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "75.42372881355932\n",
            "82.20338983050848\n",
            "83.47457627118644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gybORl3xSzU"
      },
      "source": [
        "from spacy.matcher import Matcher"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grcNWVNCgPWK"
      },
      "source": [
        "Я выбрала такой шаблон: прилагательное + существительное, предлог + существительное, наречие + прилагательное"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3oYGO28mjkk"
      },
      "source": [
        "list_of_rules = [\n",
        "    ['ADJ','NOUN'],\n",
        "    ['ADP','NOUN'],\n",
        "    ['ADV','ADJ']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQdtnqidymj4"
      },
      "source": [
        "rules = [[{\"POS\": i} for i in j] for j in list_of_rules]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7sXE5zy2cDH"
      },
      "source": [
        "list_of_rules = [\n",
        "    ['ADJ','NOUN'],\n",
        "    ['ADP','NOUN'],\n",
        "    ['ADV','ADJ']\n",
        "]\n",
        "\n",
        "rules = [[{\"POS\": i} for i in j] for j in list_of_rules]\n",
        "\n",
        "matcher = Matcher(nlp.vocab)\n",
        "matcher.add(\"rules\", [*rules], on_match=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGceBkC3yn1A"
      },
      "source": [
        "matches = matcher(document)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cgJZP-r3dw-",
        "outputId": "ba151192-5c22-4c5d-fb84-1a61ec050961"
      },
      "source": [
        "print([document[start:end].text for _, start, end in matches])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['целым рядом', 'объективных факторов', 'экономического развития', 'человеческого общества', 'второго тысячелетия', 'извечной мечты', 'международного общежития', 'от бесконечности', 'мирные условия', 'поступательное продвижение', 'по пути', 'экономического прогресса', 'от страха', 'за будущее', 'всеобщей организации', 'Атлантическая партия', '14 августа', '1941 г', 'межсоюзной конференции', '24 сентября', '1941 г', 'чрезвычайно важная', 'важная задача', 'миролюбивыми государствами', 'для организации', 'международных отношений', 'послевоенного устройства', 'межправительственным документом', 'в годы', 'мировой войны', 'международной организации', 'о дружбе', '4 декабря', '1941 г', 'справедливого мире', 'новой организацией', 'международных отношений', 'демократических стран', 'прочный союз', 'При создании', 'решающим моментом', 'международному праву', 'Союзных государств', 'В ходе', '25 апреля', '1945 г', '26 июня', '1945 г']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSASJ79dgeyM"
      },
      "source": [
        "К прошлому домашнему заданию я предложила бы такой шаблон: не + VERB, так как часто словосочетание \"не нравится\" не учитывается, а если еще убрать все стоп-слова, то частица \"не\" совсем пропадает. \n",
        "Также предложила бы шаблон : \"очень + VERB\" или \"очень + ADJ\", чтобы было различие между позитивным отзывом и нейтральным. Так как \"очень\" придает предложению эмоциональной окраски. "
      ]
    }
  ]
}